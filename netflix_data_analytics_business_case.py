# -*- coding: utf-8 -*-
"""Netflix Data analytics Business case

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1flaNhKy2mu0spC5a4BYFz8SpKk9L5Ul8
"""

#importing libraries for our purpose

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

! gdown https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/000/940/original/netflix.csv

df = pd.read_csv('netflix.csv')
df.head(5)

# lenght of dataset

len(df)

# Checking for info like non-nulls and Dtypes

df.info()

#no of numique values in our data

for i in df.columns:
  print(i,':',df[i].nunique())

# checking null values in every coulumns of our data

df.isnull().sum()

#checking the occurences of each of the ratings
df['rating'].value_counts()

col1 = df['director'].apply(lambda x:str(x).split(", ")).to_list()
col1

df_new1 = pd.DataFrame(col1,index=df['title'])
df_new1

#unnesting the directors column, i.e- creating separate lines for each director in a movie
constraint1 = df['director'].apply(lambda x:str(x).split(', ')).tolist()
df_new1 = pd.DataFrame(constraint1,index=df['title'])
df_new1 = df_new1.stack()
df_new1 = pd.DataFrame(df_new1.reset_index())
df_new1.rename(columns={0:'Directors'}, inplace=True)
df_new1.drop(columns='level_1',inplace=True)
df_new1.head()

#unnesting the directors column, i.e- creating separate lines for each director in a movie
constraint1 = df['director'].apply(lambda x:str(x).split(', ')).tolist()
df_new1 = pd.DataFrame(constraint1,index=df['title'])
df_new1 = df_new1.stack()
df_new1 = pd.DataFrame(df_new1.reset_index())
df_new1.rename(columns={0:'Directors'}, inplace=True)
df_new1.drop(columns='level_1',inplace=True)
df_new1.head()

#unnesting the Actors column, i.e- creating separate lines for each director in a movie
constraint2 = df['cast'].apply(lambda x:str(x).split(', ')).tolist()
df_new2 = pd.DataFrame(constraint2,index=df['title'])
df_new2 = df_new2.stack()
df_new2 = pd.DataFrame(df_new2.reset_index())
df_new2.drop(columns='level_1',inplace=True)
df_new2.rename(columns={0:'Actors'},inplace=True)
df_new2.head()

#unnesting the Gener column, i.e- creating separate lines for each director in a movie
constraint3 = df['listed_in'].apply(lambda x:str(x).split(", ")).tolist()
df_new3 = pd.DataFrame(constraint3,index=df['title'])
df_new3 = df_new3.stack()
df_new3 = pd.DataFrame(df_new3.reset_index())
df_new3.rename(columns={0:'Gener'},inplace=True)
df_new3.drop(columns='level_1',inplace=True)

df_new3.head()

df.head()

#unnesting the Gener column, i.e- creating separate lines for each director in a movie
constraint4 = df['country'].apply(lambda x:str(x).split(", ")).tolist()
df_new4 = pd.DataFrame(constraint4,index=df['title'])
df_new4 = df_new4.stack()
df_new4 = pd.DataFrame(df_new4.reset_index())
df_new4.rename(columns={0:'country'},inplace=True)
df_new4.drop(columns='level_1',inplace=True)
df_new4.head()

df_new5 = df_new2.merge(df_new1,on=['title'],how='inner')
df_new6 = df_new5.merge(df_new3,on=['title'],how='inner')
df_new = df_new6.merge(df_new4,on=['title'],how='inner')

df_new['Actors'].replace(['nan'],['Unknown Actor'],inplace=True)
df_new['Directors'].replace(['nan'],['Unknown Director'],inplace=True)
df_new.head()

df_new['country'].replace(['nan'],np.nan,inplace=True)

df_new.head()

df.head()

df.columns

df_final = df_new.merge(df[['show_id', 'type','title','date_added',
                            'release_year','rating','duration']],on=['title'],how='left')
df_final.head()

df_final.isnull().sum()

"""In duration column, it was observed that the nulls had values which were written in corresponding ratings column, i.e- you can't expect ratings to be in min. So the duration column nulls are replaced by corresponding values in ratings column"""

#df_final.loc[df_final['duration'].isnull(),'duration'].fillna(df_final['rating'])

df_final.loc[df_final['duration'].isnull(),'duration'] = df_final.loc[df_final['duration'].isnull(),'duration'].fillna(df_final['rating'])

df_final.loc[df_final['rating'].str.contains('min',na=False),'rating'] = 'NR'
df_final.isnull().sum()

#Ratings can't be in min, so it has been made NR(i.e- Non Rated)

df_final.loc[df_final['rating'].str.contains('min',na=False),'rating'] = 'NR'
df_final['rating'] = df_final['rating'].fillna('NR')
pd.set_option('display.max_rows',None)

df_final.isnull().sum()

#just an attempt to observe nulls in date_added column
df_final[df_final['date_added'].isnull()].head()

#date added column is imputed on the basis of release year,i.e- suppose there's a null for date_added
#when release year was 2013.So below piece of code just checks the mode of date added for release year=2013
# and imputes in place of nulls the corresponding mode

for i in df_final[df_final['date_added'].isnull()]['release_year'].unique():
  imp = df_final[df_final['release_year']==i]['date_added'].mode().values[0]
  df_final.loc[df_final['release_year']==i,'date_added'] = df_final.loc[df_final['release_year']==i,'date_added'].fillna(imp)

#country column is imputed on the basis of director,i.e- suppose there's a null for country
#when we have a director whose other movies have a country given.So below piece of code just checks the mode of
#country for the director
# and imputes in place of nulls the corresponding mode

for i in df_final[df_final['country'].isnull()]['Directors'].unique():
  if i in df_final[~df_final['country'].isnull()]['Directors'].unique():
    imp=df_final[df_final['Directors']==i]['country'].mode().values[0]
    df_final.loc[df_final['Directors']==i,'country']=df_final.loc[df_final['Directors']==i,'country'].fillna(imp)

"""So we imputed the country column on the basis of directors whose other movie titles had countries given. But there might be directors who have only one occurence in our data. In that scenario, I have used Actors as a basis. i.e- for this Actor majorly acts in movies of which country? Imputation has been done on this basis. For remaining rows, country has been filled as Unknown Country"""

#If there are still nulls, I just replace it by Unknown Country
df_final['country'].fillna('Unknown Country',inplace=True)
df_final.isnull().sum()

df_final.head()

df_final['duration'].value_counts()

#removing mins from data
df_final['duration'] = df_final['duration'].str.replace(' min',"")
df_final.head()

df_final['duration_copy'] = df_final['duration'].copy()
df_final1=df_final.copy()

df_final.loc[df_final['duration_copy'].str.contains('Seasons'),'duration_copy']



df_final1.loc[df_final1['duration_copy'].str.contains('Season'),'duration_copy']=0
df_final1['duration_copy']=df_final1['duration_copy'].astype('int')
df_final1.head()

#Visual Analysis - Univariate, Bivariate after pre-processing of the data

#Note: Pre-processing involves unnesting of the data in columns like Actor, Director, Country

df_final1['duration_copy'].describe()

#df_final1['duration'].value_counts()

# Define bins and labels
bins1 = [-1, 1, 50, 80, 100, 120, 150, 200, 315]
labels1 = ['<1', '1-50', '50-80', '80-100', '100-120', '120-150', '150-200', '200-315']

# Apply pd.cut to categorize 'duration_copy' column
df_final1['duration_copy'] = pd.cut(df_final1['duration_copy'], bins=bins1, labels=labels1)

# Display the first few rows of the dataframe
df_final1.head()

#df_final1.loc[~df_final1['duration'].str.contains('Season'), 'duration_copy']

# Replace 'duration' values that do not contain 'Season'
df_final1.loc[~df_final1['duration'].str.contains('Season'), 'duration'] = df_final1.loc[~df_final1['duration'].str.contains('Season'), 'duration_copy']

# Drop the 'duration_copy' column
df_final1.drop(['duration_copy'], axis=1, inplace=True)

# Display the first few rows
df_final1.head()

df_final1['release_Date'] = pd.to_datetime(df_final1['date_added'].str.strip(), format="%B %d, %Y")

df_final1

df_final1.dtypes

# changing the name of the column from "Gener":"Genre"

df_final1.rename(columns = {"Gener":"Genre"},inplace=True)

df_final1.groupby(['Genre']).agg({"title": "nunique"}).reset_index().sort_values(by='title', ascending=False).head(10)

"""It is clear that **international movies** are top with *2752* and 2nd top is **Dramas** and then**Comedy**"""



#The code groups data by genres, calculates the number of unique titles per genre, sorts them in descending order, and
#visualizes the results as a horizontal bar chart with genres on the y-axis and their frequencies on the x-axis.

df_genre = df_final1.groupby(['Genre']).agg({"title": "nunique"}).reset_index().sort_values(by='title', ascending=False)
plt.figure(figsize=(12,6))
plt.barh(df_genre[::-1]['Genre'], df_genre[::-1]['title'],color=['orange'])
plt.xlabel('Frequency of Genres')
plt.ylabel('Genres')
plt.show()

#number of distinct titles on the basis of type

df_final1.groupby(['type']).agg({'title':'nunique'})

df_type = df_final1.groupby(['type']).agg({'title':'nunique'}).reset_index()
plt.pie(df_type['title'],explode=(0.05,0.05),labels=df_type['type'],colors=['blue','red'],autopct='%1.1f%%')
plt.show()

"""The **movies** are top in *Netflix* than **TV shows**"""

df_final1['country'] = df_final1['country'].str.replace(',', '')
df_final1.head()

#number of distinct titles on the basis of country
df_final1.groupby(['country']).agg({"title":"nunique"}).reset_index().sort_values("title",ascending=False).head(10)

df_country = df_final1.groupby(['country']).agg({"title":"nunique"}).reset_index().sort_values("title",ascending=False).head(5)
plt.figure(figsize=(7,4))
plt.barh(df_country[::-1]['country'],df_country[::-1]['title'],color="blue")
plt.xlabel('Titles by countries')
plt.ylabel('Titles')
plt.show()

"""US,India,UK,Canada and France are leading countries in Content Creation on Netfix"""

#Numer of distinct titles on the basis of rating
df_final1.groupby(['rating']).agg({'title':'nunique'})

df_rating = df_final1.groupby(['rating']).agg({'title':'nunique'}).reset_index().sort_values('title',ascending=False)
plt.figure(figsize=(8,6))
plt.barh(df_rating[::-1]['rating'],df_rating[::-1]["title"],color=['violet'],edgecolor=['blue'])
plt.xlabel('Frequency by rating')
plt.ylabel('Rating')
plt.show()

df_final1.head()

df.groupby(['duration']).agg({"title":"nunique"}).reset_index().sort_values("title",ascending=False).head(10)

#number of distinct titles on the basis of duration
df_final1.groupby(['duration']).agg({"title":"nunique"}).reset_index().sort_values('title',ascending=False)

df_final1.groupby(['duration']).agg({'title':'nunique'}).reset_index().sort_values('title',ascending=False).head(10)

df_duration = df_final1.groupby(['duration']).agg({'title':'nunique'}).reset_index().sort_values('title',ascending=False).head(10)
plt.figure(figsize=(8,6))
plt.barh(df_duration[::-1]['duration'],df_duration[::-1]['title'],color='pink')
plt.xlabel('Frequency of Duration')
plt.ylabel('Duration')
plt.show()

df_final1['month'] = df_final1['release_Date'].dt.month
df_final1['year'] = df_final1['release_Date'].dt.year
df_final1['week_added'] = df_final1['release_Date'].dt.week
df_final1.head()

df_direcor = df_final1.groupby(['Directors']).agg({'title':'nunique'}).reset_index().sort_values('title',ascending=False)[1:30]
plt.barh(df_direcor[::-1]['Directors'],df_direcor[::-1]['title'],color='purple')
plt.xlabel("Frequency of the directors")
plt.xlabel("Directors")
plt.show()

"""Director **Rajiv Chilaka** made hightest movies in the `netflix`"""

df_actor = df_final1.groupby(['Actors']).agg({'title':'nunique'}).reset_index().sort_values('title',ascending=False)[1:30]
plt.barh(df_actor[::-1]['Actors'],df_actor[::-1]['title'],color='orange')
plt.xlabel("Frequency of the actors")
plt.xlabel("Actors")
plt.show()

"""Anupam Kher,SRK,Julie Tejwani, Naseeruddin Shah and Takahiro Sakurai occupy the top stop in Most
Watched content.

"""

#number of distinct titles on the basis of year
df_final1.groupby(['year']).agg({"title":"nunique"})

df_year = df_final1.groupby(['year']).agg({'title':'nunique'}).reset_index().sort_values('title',ascending=False)
sns.lineplot(df_year,x='year',y='title')
plt.ylabel("Movies released for year")
plt.xlabel("year")
plt.show()

"""It is clear from the year *2015* there is gradual increase in content in **Netflix**"""

df_month = df_final1.groupby(['month']).agg({'title':'nunique'}).reset_index().sort_values('title',ascending=False)
sns.lineplot(df_year,x='month',y='title')
plt.ylabel("Movies released per month")
plt.xlabel("month")
plt.show()

"""**October**, **December** and **January** are the holiday months so there us high release in content.


"""

df_week = df_final1.groupby(['week_added']).agg({'title':'nunique'}).reset_index()
sns.lineplot(df_week,x='week_added',y='title')
plt.ylabel("Movies released per week")
plt.xlabel("week")
plt.show()

"""4Th week is the most content released week of the month."""

